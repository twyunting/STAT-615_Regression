---
title: "Lab 9 # version 2"
author: "Yunting Chiu"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# R Lab 9

```{r}
# read the data from the web
autompg = read.table(
  "http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data",
  quote = "\"",
  comment.char = "",
  stringsAsFactors = FALSE)
# give the dataframe headers
colnames(autompg) = c("mpg", "cyl", "disp", "hp", "wt", "acc", "year", "origin", "name") # remove missing data, which is stored as "?"
autompg = subset(autompg, autompg$hp != "?")
# remove the plymouth reliant, as it causes some issues
autompg = subset(autompg, autompg$name != "plymouth reliant")
# give the dataset row names, based on the engine, year and name
rownames(autompg) = paste(autompg$cyl, "cylinder", autompg$year, autompg$name)
# remove the variable for name, as well as origin
autompg = subset(autompg, select = c("mpg", "cyl", "disp", "hp", "wt", "acc", "year")) # change horsepower from character to numeric
autompg$hp = as.numeric(autompg$hp)
# check final structure of data
str(autompg)
```

```{r}
head(autompg)
```

# Task 1
Use the lm function and provide estimates of $\beta0$, $\beta1$, and $\beta2$.
```{r}
mpg_model <- lm(mpg ~ wt+year, data = autompg)
coef(mpg_model) # b0, b1, b2
```

# Task 2
```{r}
n = nrow(autompg) # 390 observations
p = length(coef(mpg_model)) # b0, b1, b2
X = cbind(rep(1, n), autompg$wt, autompg$year) # x as defined above
y = autompg$mpg # column vector

# solve: a %*% x = b for x, where b can be either a vector or a matrix.
beta_hat = solve(t(X) %*% X) %*% t(X) %*% y # equation
# transport  = t(X), solve : find the inverse
beta_hat
```

# Task 3
- In statistics, the residual sum of squares (RSS), also known as the sum of squared residuals (SSR) or the sum of squared estimate of errors (SSE), is the sum of the squares of residuals (deviations predicted from actual empirical values of data).
```{r}
MSE <- sum(residuals(mpg_model)^2)/(n-p) # sum of residual square 
sqrt(MSE)
```
- Second method
```{r}
yhat = X %*% solve(t(X) %*% X) %*% t(X) %*% y
e = y - yhat
# e
sqrt(t(e) %*% e / (n-p))
```

# Task 4
The Adjusted R-squared is 0.8082355, meaning that the model has 81% of variability being explained. The observed variation `in miles per gallon` is explained of 81% by the linear relationship with other two predictors (`weight` and `year`.)
```{r}
summary(mpg_model)$r.squared
```


